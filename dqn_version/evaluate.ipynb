{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9f6c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from model import ConvolutionalNeuralNetwork\n",
    "from tictactoeenv import TicTacToeEnv\n",
    "\n",
    "# Ha a notebookot a dqn_version mappából futtatod, ez jó lesz:\n",
    "BASE_DIR = os.getcwd()\n",
    "MODELS_DIR = os.path.join(BASE_DIR, \"trained_models\")\n",
    "MODEL_X_PATH = os.path.join(MODELS_DIR, \"trained_model_X.pth\")\n",
    "MODEL_O_PATH = os.path.join(MODELS_DIR, \"trained_model_O.pth\")\n",
    "\n",
    "MODEL_X_PATH, MODEL_O_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1abb9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalAgent:\n",
    "    \"\"\"\n",
    "    Egyszerű értékelő ügynök, aki csak greedy módon választ akciót\n",
    "    egy betanított ConvolutionalNeuralNetwork segítségével.\n",
    "    Nincs tanulás, nincs epsilon.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_path: str, player_mark: int) -> None:\n",
    "        self.player_mark = player_mark  # +1 = X, -1 = O\n",
    "        self.model = ConvolutionalNeuralNetwork()\n",
    "        self.model.load_state_dict(\n",
    "            torch.load(model_path, map_location=torch.device(\"cpu\"))\n",
    "        )\n",
    "        self.model.eval()\n",
    "\n",
    "    def select_action(self, state: np.ndarray) -> int | None:\n",
    "        state = np.array(state, dtype=np.float32)\n",
    "        flat = state.flatten()\n",
    "        valid = [i for i, v in enumerate(flat) if v == 0]\n",
    "\n",
    "        if not valid:\n",
    "            return None\n",
    "\n",
    "        state_t = torch.from_numpy(state).float().unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            q_vals = self.model(state_t)[0]\n",
    "\n",
    "        # Érvénytelen lépések maszkolása\n",
    "        mask = torch.full_like(q_vals, float(\"-inf\"))\n",
    "        mask[valid] = q_vals[valid]\n",
    "        action = int(torch.argmax(mask).item())\n",
    "        return action\n",
    "\n",
    "\n",
    "def select_random_action(state: np.ndarray) -> int | None:\n",
    "    flat = state.flatten()\n",
    "    valid = [i for i, v in enumerate(flat) if v == 0]\n",
    "    if not valid:\n",
    "        return None\n",
    "    return int(np.random.choice(valid))\n",
    "\n",
    "\n",
    "def play_single_episode(\n",
    "    env: TicTacToeEnv,\n",
    "    agent_x: EvalAgent | None = None,\n",
    "    agent_o: EvalAgent | None = None,\n",
    "    random_x: bool = False,\n",
    "    random_o: bool = False,\n",
    ") -> tuple[str, float, float]:\n",
    "    \"\"\"\n",
    "    Lejátszik egy epizódot a megadott beállításokkal.\n",
    "\n",
    "    Visszatér:\n",
    "        winner: \"X\", \"O\" vagy \"draw\"\n",
    "        episode_reward_x: X teljes epizód-jutalma\n",
    "        episode_reward_o: O teljes epizód-jutalma\n",
    "    \"\"\"\n",
    "    env.reset()\n",
    "    current_player = 1  # X kezd\n",
    "    episode_reward_x = 0.0\n",
    "    episode_reward_o = 0.0\n",
    "\n",
    "    winner = \"draw\"\n",
    "\n",
    "    max_steps = env.size * env.size + 10\n",
    "    step_count = 0\n",
    "\n",
    "    while True:\n",
    "        step_count += 1\n",
    "        state = env.get_board_actual_state()\n",
    "\n",
    "        if current_player == 1:\n",
    "            if random_x:\n",
    "                action = select_random_action(state)\n",
    "            else:\n",
    "                action = agent_x.select_action(state)\n",
    "        else:\n",
    "            if random_o:\n",
    "                action = select_random_action(state)\n",
    "            else:\n",
    "                action = agent_o.select_action(state)\n",
    "\n",
    "        if action is None:\n",
    "            # Nincsenek legális lépések → fallback: döntetlen\n",
    "            winner = \"draw\"\n",
    "            break\n",
    "\n",
    "        reward, done, is_illegal = env.play_step(action, current_player)\n",
    "\n",
    "        if current_player == 1:\n",
    "            episode_reward_x += reward\n",
    "        else:\n",
    "            episode_reward_o += reward\n",
    "\n",
    "        if done:\n",
    "            if reward > 0:\n",
    "                winner = \"X\" if current_player == 1 else \"O\"\n",
    "            else:\n",
    "                # env -2-t ad döntetlenre\n",
    "                winner = \"draw\"\n",
    "            break\n",
    "\n",
    "        if step_count >= max_steps:\n",
    "            winner = \"draw\"\n",
    "            break\n",
    "\n",
    "        # játékos váltás\n",
    "        current_player = -current_player\n",
    "\n",
    "    return winner, episode_reward_x, episode_reward_o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0157cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval_self_play(num_episodes: int = 1000):\n",
    "    env = TicTacToeEnv()\n",
    "    agent_x = EvalAgent(MODEL_X_PATH, player_mark=1)\n",
    "    agent_o = EvalAgent(MODEL_O_PATH, player_mark=-1)\n",
    "\n",
    "    wins_x = 0\n",
    "    wins_o = 0\n",
    "    draws = 0\n",
    "    rewards_x: list[float] = []\n",
    "    rewards_o: list[float] = []\n",
    "\n",
    "    for _ in range(num_episodes):\n",
    "        winner, ep_rx, ep_ro = play_single_episode(\n",
    "            env,\n",
    "            agent_x=agent_x,\n",
    "            agent_o=agent_o,\n",
    "            random_x=False,\n",
    "            random_o=False,\n",
    "        )\n",
    "        if winner == \"X\":\n",
    "            wins_x += 1\n",
    "        elif winner == \"O\":\n",
    "            wins_o += 1\n",
    "        else:\n",
    "            draws += 1\n",
    "\n",
    "        rewards_x.append(ep_rx)\n",
    "        rewards_o.append(ep_ro)\n",
    "\n",
    "    return {\n",
    "        \"scenario\": \"Self-play: X ügynök vs O ügynök\",\n",
    "        \"episodes\": num_episodes,\n",
    "        \"x_wins\": wins_x,\n",
    "        \"o_wins\": wins_o,\n",
    "        \"draws\": draws,\n",
    "        \"avg_reward_x\": float(np.mean(rewards_x)),\n",
    "        \"avg_reward_o\": float(np.mean(rewards_o)),\n",
    "    }\n",
    "\n",
    "\n",
    "def run_eval_vs_random(num_episodes: int = 1000, rl_as: str = \"X\"):\n",
    "    env = TicTacToeEnv()\n",
    "\n",
    "    rl_as = rl_as.upper()\n",
    "    if rl_as == \"X\":\n",
    "        agent_x = EvalAgent(MODEL_X_PATH, player_mark=1)\n",
    "        agent_o = None\n",
    "        random_x = False\n",
    "        random_o = True\n",
    "        label = \"X ügynök vs véletlen O\"\n",
    "    else:\n",
    "        agent_x = None\n",
    "        agent_o = EvalAgent(MODEL_O_PATH, player_mark=-1)\n",
    "        random_x = True\n",
    "        random_o = False\n",
    "        label = \"Véletlen X vs O ügynök\"\n",
    "\n",
    "    wins_x = 0\n",
    "    wins_o = 0\n",
    "    draws = 0\n",
    "    rewards_x: list[float] = []\n",
    "    rewards_o: list[float] = []\n",
    "\n",
    "    for _ in range(num_episodes):\n",
    "        winner, ep_rx, ep_ro = play_single_episode(\n",
    "            env,\n",
    "            agent_x=agent_x,\n",
    "            agent_o=agent_o,\n",
    "            random_x=random_x,\n",
    "            random_o=random_o,\n",
    "        )\n",
    "        if winner == \"X\":\n",
    "            wins_x += 1\n",
    "        elif winner == \"O\":\n",
    "            wins_o += 1\n",
    "        else:\n",
    "            draws += 1\n",
    "\n",
    "        rewards_x.append(ep_rx)\n",
    "        rewards_o.append(ep_ro)\n",
    "\n",
    "    return {\n",
    "        \"scenario\": label,\n",
    "        \"episodes\": num_episodes,\n",
    "        \"x_wins\": wins_x,\n",
    "        \"o_wins\": wins_o,\n",
    "        \"draws\": draws,\n",
    "        \"avg_reward_x\": float(np.mean(rewards_x)),\n",
    "        \"avg_reward_o\": float(np.mean(rewards_o)),\n",
    "    }\n",
    "\n",
    "\n",
    "def run_eval_random_vs_random(num_episodes: int = 1000):\n",
    "    \"\"\"\n",
    "    Sanity check: mindkét játékos véletlenül lép.\n",
    "    \"\"\"\n",
    "    env = TicTacToeEnv()\n",
    "\n",
    "    wins_x = 0\n",
    "    wins_o = 0\n",
    "    draws = 0\n",
    "    rewards_x: list[float] = []\n",
    "    rewards_o: list[float] = []\n",
    "\n",
    "    for _ in range(num_episodes):\n",
    "        winner, ep_rx, ep_ro = play_single_episode(\n",
    "            env,\n",
    "            agent_x=None,\n",
    "            agent_o=None,\n",
    "            random_x=True,\n",
    "            random_o=True,\n",
    "        )\n",
    "        if winner == \"X\":\n",
    "            wins_x += 1\n",
    "        elif winner == \"O\":\n",
    "            wins_o += 1\n",
    "        else:\n",
    "            draws += 1\n",
    "\n",
    "        rewards_x.append(ep_rx)\n",
    "        rewards_o.append(ep_ro)\n",
    "\n",
    "    return {\n",
    "        \"scenario\": \"Véletlen X vs véletlen O\",\n",
    "        \"episodes\": num_episodes,\n",
    "        \"x_wins\": wins_x,\n",
    "        \"o_wins\": wins_o,\n",
    "        \"draws\": draws,\n",
    "        \"avg_reward_x\": float(np.mean(rewards_x)),\n",
    "        \"avg_reward_o\": float(np.mean(rewards_o)),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95221353",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPISODES = 1000\n",
    "\n",
    "res_self = run_eval_self_play(NUM_EPISODES)\n",
    "res_x_rand = run_eval_vs_random(NUM_EPISODES, rl_as=\"X\")\n",
    "res_o_rand = run_eval_vs_random(NUM_EPISODES, rl_as=\"O\")\n",
    "res_rand_rand = run_eval_random_vs_random(NUM_EPISODES)\n",
    "\n",
    "results = [res_self, res_x_rand, res_o_rand, res_rand_rand]\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049bab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hu = df.rename(columns={\n",
    "    \"scenario\": \"Szenárió\",\n",
    "    \"episodes\": \"Epizódok száma\",\n",
    "    \"x_wins\": \"X győzelmek\",\n",
    "    \"o_wins\": \"O győzelmek\",\n",
    "    \"draws\": \"Döntetlenek\",\n",
    "    \"avg_reward_x\": \"X átlagos epizód-jutalma\",\n",
    "    \"avg_reward_o\": \"O átlagos epizód-jutalma\",\n",
    "})\n",
    "df_hu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed1fd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x = np.arange(len(df_hu))\n",
    "width = 0.25\n",
    "\n",
    "ax.bar(x - width, df_hu[\"X győzelmek\"], width, label=\"X győzelmek\")\n",
    "ax.bar(x,         df_hu[\"O győzelmek\"], width, label=\"O győzelmek\")\n",
    "ax.bar(x + width, df_hu[\"Döntetlenek\"], width, label=\"Döntetlenek\")\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(df_hu[\"Szenárió\"], rotation=15, ha=\"right\")\n",
    "\n",
    "ax.set_ylabel(\"Partik száma\")\n",
    "ax.set_xlabel(\"Szcenárió\")\n",
    "ax.set_title(\"Győzelmek és döntetlenek különböző szcenáriókban\")\n",
    "\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74edc581",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x = np.arange(len(df_hu))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, df_hu[\"X átlagos epizód-jutalma\"], width, label=\"X átlagos jutalma\")\n",
    "ax.bar(x + width/2, df_hu[\"O átlagos epizód-jutalma\"], width, label=\"O átlagos jutalma\")\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(df_hu[\"Szenárió\"], rotation=15, ha=\"right\")\n",
    "\n",
    "ax.set_ylabel(\"Átlagos epizód-jutalom\")\n",
    "ax.set_xlabel(\"Szcenárió\")\n",
    "ax.set_title(\"Átlagos epizód-jutalmak X és O számára\")\n",
    "\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
